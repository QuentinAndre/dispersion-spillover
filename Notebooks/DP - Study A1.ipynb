{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook pre-processes the data of Study 1 in the Appendix (the \"Range\" study).\n",
    "\n",
    "Click the \"Show Code\" buttons to see the code associated with each output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "STUDY_NAME = \"Study A1\"\n",
    "    \n",
    "def print_collection_information(df):\n",
    "    startstring = df.sort_values(\"startdate\").startdate.iloc[0].strftime(\"%B %d, %Y at %H:%M %p\")\n",
    "    endstring = df.sort_values(\"enddate\").enddate.iloc[-1].strftime(\"%B %d, %Y at %H:%M %p\")\n",
    "    return f\"{STUDY_NAME} was started on {startstring} and ended on {endstring}.\"\n",
    "\n",
    "\n",
    "df = pd.read_pickle(f\"../Data/{STUDY_NAME}/RawData.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data collection information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Study A1 was started on July 31, 2019 at 16:04 PM and ended on July 31, 2019 at 21:14 PM.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_collection_information(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of participants in database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "399"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of valid participants:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "395\n"
     ]
    }
   ],
   "source": [
    "def has_both_allocations(x):\n",
    "    \"\"\"\n",
    "    Check if both allocations were correctly recorded.\n",
    "    \"\"\"\n",
    "    alloc1_recorded = (len(x.alloc_item_one) == 25)\n",
    "    alloc2_recorded = (len(x.alloc_item_two) == 25)\n",
    "    return alloc1_recorded & alloc2_recorded\n",
    "\n",
    "df_clean = df[df.apply(has_both_allocations, axis=1)].copy()\n",
    "print(df_clean.shape [0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_allocation_to_distribution(allocation, buckets, isstr=False):\n",
    "    \"\"\"\n",
    "    Takes an allocation of balls to buckets, and a list of buckets.\n",
    "    Return the corresponding distribution of values.\n",
    "    \n",
    "    Example: \n",
    "        buckets = [1, 2, 3, 4, 5]\n",
    "        x = \"0, 3, 1, 2, 1\"\n",
    "        dist = convert_allocation_to_distribution(x, buckets)\n",
    "        print(dist) -> (2, 2, 2, 3, 4, 4, 5)\n",
    "    \"\"\"\n",
    "    if isstr:\n",
    "        arr = allocation.split(\",\")\n",
    "    else:\n",
    "        arr = allocation\n",
    "    if len(arr) != len(buckets):\n",
    "        raise ValueError(\"The number of buckets should match the length of the allocations.\")\n",
    "    values = np.repeat(buckets, arr)\n",
    "    return values\n",
    "\n",
    "# Converting the allocations into distributions, and storing them in respective columns, before dropping the \"allocation\" columns\n",
    "df_clean[\"dist_item_one\"] = df_clean.alloc_item_one.apply(convert_allocation_to_distribution, buckets=np.arange(2, 52, 2))\n",
    "df_clean[\"dist_item_two\"] = df_clean.alloc_item_two.apply(convert_allocation_to_distribution, buckets=np.arange(2, 52, 2))\n",
    "df_clean.drop(columns=[\"alloc_item_one\", \"alloc_item_two\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "790\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../Data/Appendix Study 1/CleanData.pickle'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-91666b400348>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m#Number of participants times two distributions:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_long\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mdf_long\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_pickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"../Data/Appendix Study 1/CleanData.pickle\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\.conda\\envs\\researchshared\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_pickle\u001b[1;34m(self, path, compression, protocol)\u001b[0m\n\u001b[0;32m   2723\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpickle\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mto_pickle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2724\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2725\u001b[1;33m         \u001b[0mto_pickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcompression\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2726\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2727\u001b[0m     def to_clipboard(\n",
      "\u001b[1;32m~\\.conda\\envs\\researchshared\\lib\\site-packages\\pandas\\io\\pickle.py\u001b[0m in \u001b[0;36mto_pickle\u001b[1;34m(obj, filepath_or_buffer, compression, protocol)\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mcompression\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"infer\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[0mcompression\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m     \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_handle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"wb\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcompression\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mprotocol\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m         \u001b[0mprotocol\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mHIGHEST_PROTOCOL\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\researchshared\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[0;32m    432\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    433\u001b[0m             \u001b[1;31m# Binary mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 434\u001b[1;33m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    435\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    436\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../Data/Appendix Study 1/CleanData.pickle'"
     ]
    }
   ],
   "source": [
    "# Each participant reported two distributions (item_one and item_two), pivoting the data in long form.\n",
    "df_long = pd.wide_to_long(df_clean, stubnames=[\"wine\", \"history\", \"dist\"], i=\"pid\", j=\"value\", suffix=\"\\\\D+\", sep=\"_\").reset_index()\n",
    "\n",
    "# Coding if the reported distribution was for the focal distribution or the distractor\n",
    "df_long[\"is_distractor\"] = (df_long.name_distractor == df_long.wine)\n",
    "\n",
    "#Number of participants times two distributions:\n",
    "print(df_long.shape[0])\n",
    "df_long.to_pickle(\"../Data/Appendix Study 1/CleanData.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivoting the distributions in long form: one line per value per distribution per participant.\n",
    "df_dist = df_long.set_index(['pid', 'turkid', 'name_distractor', 'is_distractor', 'wine', 'shape_distractor'])['dist'].apply(pd.Series).stack().reset_index()\n",
    "df_dist.columns = ['pid', 'turkid', 'name_manipulated', 'is_manipulated', 'wine', \n",
    "                             'shape_manipulated', \"value_id\", \"value\"]\n",
    "print(df_dist.shape[0])\n",
    "\n",
    "df_dist.to_pickle(\"../Data/Appendix Study 1/LongData.pickle\")\n",
    "df_dist.to_csv(\"../Data/Appendix Study 1/LongData.csv\", index=None)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "toc_cell": false,
   "toc_number_sections": false,
   "toc_section_display": "block",
   "toc_threshold": 6,
   "toc_window_display": true
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false,
  "toc_position": {
   "height": "378px",
   "left": "1662.38px",
   "right": "10.6167px",
   "top": "120px",
   "width": "247px"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
