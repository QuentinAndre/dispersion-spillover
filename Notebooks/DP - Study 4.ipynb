{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook pre-processes the data of Study 4 of the paper.\n",
    "\n",
    "Click the \"Show Code\" buttons to see the code associated with each output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import janitor\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "\n",
    "STUDY_NAME = \"Study 4\"\n",
    "\n",
    "def cet_to_utc(dt):\n",
    "    local_tz = pytz.timezone('CET')\n",
    "    target_tz = pytz.timezone('UTC')\n",
    "    dt = datetime.strptime(dt, \"%d/%m/%Y %H:%M\")\n",
    "    return target_tz.normalize(local_tz.localize(dt))\n",
    "\n",
    "def print_collection_information(df):\n",
    "    starttime = df.sort_values(\"StartDate\").StartDate.iloc[0]\n",
    "    endtime = df.sort_values(\"EndDate\").EndDate.iloc[-1]\n",
    "    startstring = cet_to_utc(starttime).strftime(\"%B %d, %Y at %H:%M %p\")\n",
    "    endstring = cet_to_utc(endtime).strftime(\"%B %d, %Y at %H:%M %p\")\n",
    "    return f\"{STUDY_NAME} was started on {startstring} and ended on {endstring}.\"\n",
    "\n",
    "df = pd.read_csv(f\"../Data/{STUDY_NAME}/RawData.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of participants in raw Qualtrics Export:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "301"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data collection information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Study 4 was started on June 27, 2019 at 14:14 PM and ended on June 27, 2019 at 16:01 PM.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_collection_information(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data collection started on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "df[\"Condition\"] = df.dispersion.map({\"same\": \"Equal dispersion\", \"higher\": \"Higher dispersion\"}) # Nicer condition labels\n",
    "df[\"Label_Category\"] = df.manipulated.map({\"florida\": \"Colorado\", \"colorado\": \"Florida\"})\n",
    "\n",
    "df[\"Memory_Avg\"] = df[[\"Avg_Florida\", \"Avg_Colorado\"]].fillna(0).sum(axis=1) # Reported average\n",
    "df[\"Memory_Min\"] = df[[\"Min_Colorado\", \"Avg_Colorado.1\"]].fillna(0).sum(axis=1) # Reported minimum price\n",
    "\n",
    "df[\"Below_True_Min\"] = (df.Memory_Min < 240)*1 # Dummy coding if minimum price below true minimu price\n",
    "\n",
    "for l in range(1, 6):\n",
    "    df[f\"PickLikelihood_{l}\"] = df[[f'{l}_WTA_Colorado', f'{l}_WTA_Florida']].fillna(0).sum(axis=1) # Likelihood of picking each price\n",
    "    \n",
    "cols = ['ResponseId', 'Label_Category', 'Condition', 'Memory_Avg', 'Memory_Min', 'Below_True_Min',\n",
    "        'PickLikelihood_1', 'PickLikelihood_2', 'PickLikelihood_3', 'PickLikelihood_4', 'PickLikelihood_5']\n",
    "\n",
    "df = df[cols].rename_columns({\"ResponseId\": \"turkid\"}).clean_names() # Subsetting columns of interests\n",
    "\n",
    "df.to_csv(f\"../Data/{STUDY_NAME}/CleanData.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1505\n"
     ]
    }
   ],
   "source": [
    "# Data in long form: one line per evaluation of LTA and per participant\n",
    "\n",
    "df_long = pd.melt(df, id_vars=[\"turkid\", \"condition\", \"label_category\", \"memory_min\", \"memory_avg\"], \n",
    "                  value_vars=[f\"picklikelihood_{i}\" for i in range(1, 6)], \n",
    "                  value_name=\"LTA\", \n",
    "                  var_name=\"offer\")\n",
    "\n",
    "# Mapping the offer values\n",
    "df_long[\"offer\"] = df_long.offer.apply(lambda x: x[-1]).map({\"1\":280, \"2\":260, \"3\":240, \"4\":220, \"5\":200})\n",
    "\n",
    "# Evaluating consistency of preferences\n",
    "is_consistent = df_long.sort_values([\"turkid\", \"offer\"]).groupby(\"turkid\")[\"LTA\"].apply(lambda x: all(np.diff(x)<=0))\n",
    "is_consistent.name = \"has_consistent_prefs\"\n",
    "df_long = df_long.merge(is_consistent, on=\"turkid\")\n",
    "df_long.to_csv(f\"../Data/{STUDY_NAME}/LongData.csv\", index=False)\n",
    "print(df_long.shape[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
