{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook pre-processes the data of Study 3 of the paper.\n",
    "\n",
    "Click the \"Show Code\" buttons to see the code associated with each output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "STUDY_NAME = \"Study 3\"\n",
    "\n",
    "def print_collection_information(df):\n",
    "    startstring = df.sort_values(\"startdate\").startdate.iloc[0].strftime(\"%B %d, %Y at %H:%M %p\")\n",
    "    endstring = df.sort_values(\"enddate\").enddate.iloc[-1].strftime(\"%B %d, %Y at %H:%M %p\")\n",
    "    return f\"{STUDY_NAME} was started on {startstring} and ended on {endstring}.\"\n",
    "\n",
    "\n",
    "df = pd.read_pickle(f\"../Data/{STUDY_NAME}/RawData.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data collection information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Study 3 was started on February 07, 2020 at 16:59 PM and ended on February 07, 2020 at 18:58 PM.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_collection_information(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of participants in database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of valid participants:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "290\n"
     ]
    }
   ],
   "source": [
    "def has_both_allocations(x):\n",
    "    \"\"\"\n",
    "    Check if both allocations were correctly recorded.\n",
    "    \"\"\"\n",
    "    alloc1_recorded = len(x.alloc_item_one) == 25\n",
    "    alloc2_recorded = len(x.alloc_item_two) == 25\n",
    "    return alloc1_recorded & alloc2_recorded\n",
    "\n",
    "\n",
    "df_clean = df[df.apply(has_both_allocations, axis=1) & (df.turkid != \"TEST\")].copy()\n",
    "print(df_clean.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_allocation_to_distribution(allocation, buckets, isstr=False):\n",
    "    \"\"\"\n",
    "    Takes an allocation of balls to buckets, and a list of buckets.\n",
    "    Return the corresponding distribution of values.\n",
    "    \n",
    "    Example: \n",
    "        buckets = [1, 2, 3, 4, 5]\n",
    "        x = \"0, 3, 1, 2, 1\"\n",
    "        dist = convert_allocation_to_distribution(x, buckets)\n",
    "        print(dist) -> (2, 2, 2, 3, 4, 4, 5)\n",
    "    \"\"\"\n",
    "    if isstr:\n",
    "        arr = allocation.split(\",\")\n",
    "    else:\n",
    "        arr = allocation\n",
    "    if len(arr) != len(buckets):\n",
    "        raise ValueError(\n",
    "            \"The number of buckets should match the length of the allocations.\"\n",
    "        )\n",
    "    values = np.repeat(buckets, arr)\n",
    "    return values\n",
    "\n",
    "\n",
    "# Converting the allocations into distributions, and storing them in respective columns, before dropping the \"allocation\" columns\n",
    "df_clean[\"dist_item_one\"] = df_clean.alloc_item_one.apply(\n",
    "    convert_allocation_to_distribution, buckets=np.arange(1, 51, 2)\n",
    ")\n",
    "df_clean[\"dist_item_two\"] = df_clean.alloc_item_two.apply(\n",
    "    convert_allocation_to_distribution, buckets=np.arange(1, 51, 2)\n",
    ")\n",
    "df_clean.drop(columns=[\"alloc_item_one\", \"alloc_item_two\"], inplace=True)\n",
    "df_clean[\"name_second_item\"] = df_clean.name_first_item.map({\"White\": \"Red\", \"Red\":\"White\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "580\n"
     ]
    }
   ],
   "source": [
    "# Each participant reported two distributions (item_one and item_two), pivoting the data in long form.\n",
    "df_long = pd.wide_to_long(\n",
    "    df_clean,\n",
    "    stubnames=[\"dist\"],\n",
    "    i=\"pid\",\n",
    "    j=\"item_name\",\n",
    "    suffix=\"(!?item_one|item_two)\",\n",
    "    sep=\"_\",\n",
    ").reset_index()\n",
    "df_long[\"item_name\"] = df_long[\"item_name\"].map(\n",
    "    {\"item_one\": \"first_item\", \"item_two\": \"second_item\"}\n",
    ")\n",
    "df_long[\"item_id\"] = df_long.apply(lambda x: x[\"name_\" + x.item_name], axis=1)\n",
    "\n",
    "# Coding if the reported distribution was for the focal distribution or the distractor\n",
    "df_long[\"is_manipulated\"] = df_long.name_manipulated == df_long.item_id\n",
    "df_long[\"is_first\"] = df_long.name_first_item == df_long.item_id\n",
    "# Number of participants times two distributions:\n",
    "print(df_long.shape[0])\n",
    "df_long.to_pickle(f\"../Data/{STUDY_NAME}/CleanData.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15080\n"
     ]
    }
   ],
   "source": [
    "# Pivoting the distributions in long form: one line per value per distribution per participant.\n",
    "df_dist = (\n",
    "    df_long.set_index(\n",
    "        [\"turkid\", \"name_manipulated\", \"is_manipulated\", \"sd_manipulated\", \"is_first\"]\n",
    "    )[\"dist\"]\n",
    "    .apply(pd.Series)\n",
    "    .stack()\n",
    "    .reset_index()\n",
    ")\n",
    "df_dist.columns = [\n",
    "    \"turkid\",\n",
    "    \"name_manipulated\",\n",
    "    \"is_manipulated\",\n",
    "    \"sd_manipulated\",\n",
    "    \"is_first\",\n",
    "    \"value_id\",\n",
    "    \"value\",\n",
    "]\n",
    "print(df_dist.shape[0])\n",
    "df_dist.to_csv(f\"../Data/{STUDY_NAME}/LongData.csv\", index=None)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "toc_cell": false,
   "toc_number_sections": false,
   "toc_section_display": "block",
   "toc_threshold": 6,
   "toc_window_display": true
  },
  "toc_position": {
   "height": "378px",
   "left": "1662.38px",
   "right": "10.6167px",
   "top": "120px",
   "width": "247px"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
